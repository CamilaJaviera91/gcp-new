services:
  postgres:
    image: postgres:15
    container_name: postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    networks:
      - airflow_network

  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow-webserver
    restart: always
    environment:
      AIRFLOW__CORE__EXECUTOR: ${AIRFLOW__CORE__EXECUTOR}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW__DATABASE__SQL_ALCHEMY_CONN}
      AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW__CORE__LOAD_EXAMPLES}
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_SCHEMA: ${POSTGRES_SCHEMA}
      GOOGLE_CREDENTIALS_PATH: ${GOOGLE_CREDENTIALS_PATH}
      BQ_PROJECT_ID: ${BQ_PROJECT_ID}
      BQ_DATASET: ${BQ_DATASET}

    volumes:
      - ./dags:/opt/airflow/dags:z
      - ./scripts:/opt/airflow/scripts:z
      - ./dbt_project:/opt/airflow/dbt_project:z
      - ./files:/opt/airflow/files:z
      - ./credentials/auth.json:/home/airflow/gcloud/auth.json:z
    ports:
      - "8080:8080"
    depends_on:
      - postgres
    networks:
      - airflow_network
    command: webserver

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow-scheduler
    restart: always
    depends_on:
      - postgres
    volumes:
      - ./dags:/opt/airflow/dags:z
      - ./scripts:/opt/airflow/scripts:z
      - ./dbt_project:/opt/airflow/dbt_project:z
      - ./files:/opt/airflow/files:z
      - ./credentials/auth.json:/home/airflow/gcloud/auth.json:z
    environment:
      AIRFLOW__CORE__EXECUTOR: ${AIRFLOW__CORE__EXECUTOR}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW__DATABASE__SQL_ALCHEMY_CONN}
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_SCHEMA: ${POSTGRES_SCHEMA}
      GOOGLE_CREDENTIALS_PATH: ${GOOGLE_CREDENTIALS_PATH}
      BQ_PROJECT_ID: ${BQ_PROJECT_ID}
      BQ_DATASET: ${BQ_DATASET}
    networks:
      - airflow_network
    command: scheduler

  airflow-init:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow-init
    depends_on:
      - postgres      
    volumes:
      - ./dags:/opt/airflow/dags:z
      - ./scripts:/opt/airflow/scripts:z
      - ./dbt_project:/opt/airflow/dbt_project:z
      - ./files:/opt/airflow/files:z
      - ./credentials/auth.json:/home/airflow/gcloud/auth.json:z
    environment:
      AIRFLOW__CORE__EXECUTOR: ${AIRFLOW__CORE__EXECUTOR}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW__DATABASE__SQL_ALCHEMY_CONN}
    entrypoint: >
      bash -c "airflow db init &&
               airflow users create --username admin --password admin --firstname Camila --lastname Mu√±oz --role Admin --email camila@example.com"
    networks:
      - airflow_network

volumes:
  pgdata:

networks:
  airflow_network:
  